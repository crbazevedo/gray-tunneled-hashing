# Gray-Tunneled Hashing (GTH)

A novel binary hashing approach that optimizes the assignment of embeddings to binary codes by solving a Quadratic Assignment Problem (QAP), enabling efficient approximate nearest neighbor search with improved recall.

## üéØ Overview

Gray-Tunneled Hashing (GTH) is a distribution-aware hashing method that treats binary code assignment as an explicit optimization problem. Unlike traditional approaches that assign codes via simple quantization, GTH optimizes the mapping to align Hamming distances in binary space with semantic distances in the original embedding space.

### Key Results (Sprint 8)

- **GTH outperforms baselines in 7/8 configurations** with recall improvements of **+15% to +91%**
- Best configuration achieves **8.2% recall** vs **4.3% baseline** (+90.7% improvement)
- Works particularly well with **Hyperplane LSH** (+61% to +91% improvements)

## üìö Table of Contents

- [Theory](#theory)
- [Architecture](#architecture)
- [Project Structure](#project-structure)
- [Core Classes](#core-classes)
- [API Reference](#api-reference)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Experiments](#experiments)

## üßÆ Theory

### Problem Formulation

GTH solves a **Quadratic Assignment Problem (QAP)** where:

- **Locations**: Hypercube vertices (binary codes in `{0,1}^n`)
- **Facilities**: Embeddings from the dataset
- **Flow**: Query-neighbor co-occurrence probabilities
- **Distances**: Semantic dissimilarity (cosine distance)

**Objective Function (J(œÜ))**:

```
J(œÜ) = Œ£_{i,j} œÄ_i ¬∑ w_ij ¬∑ E[d_H(œÜ(h(q)), œÜ(h(x))) | q‚ààbucket_i, x‚ààbucket_j]
```

where:
- `œÄ_i`: Query prior for bucket `i`
- `w_ij`: Neighbor co-occurrence weight between buckets `i` and `j`
- `œÜ`: GTH permutation mapping bucket codes to optimized binary codes
- `h`: LSH encoder mapping embeddings to bucket codes
- `d_H`: Hamming distance

### Key Insight

The assignment of embeddings to hypercube vertices matters critically. If semantically similar embeddings are mapped to Hamming-nearby codes, a single bit flip results in limited distortion, improving search quality.

**Visualization**:

```
Embedding Space (‚Ñù·µà)          Hypercube Q‚Çô (Binary Codes)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ          ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    w‚ÇÅ ‚óè                       000 ‚îÄ‚îÄ 001
       ‚îÇ                        ‚îÇ     ‚îÇ
    w‚ÇÇ ‚óè ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ semantic ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 010 ‚îÄ‚îÄ 011   Hamming-1 edges
       ‚îÇ   distance              ‚îÇ     ‚îÇ
    w‚ÇÉ ‚óè                       100 ‚îÄ‚îÄ 101
       ‚îÇ                        ‚îÇ     ‚îÇ
    w‚ÇÑ ‚óè                       110 ‚îÄ‚îÄ 111
       
Goal: Find permutation œÜ such that
  Hamming-1 neighbors ‚Üî Semantically similar embeddings
```

### Optimization

GTH uses **hill climbing with 2-swap moves** to minimize J(œÜ):

1. **Initialization**: Random or identity permutation
2. **Hill Climbing**: Iteratively swap bucket code assignments to reduce cost
3. **Block Tunneling** (optional): Reoptimize small subsets to escape local minima

The 2-swap operator transposes the binary codes assigned to two buckets, with efficient delta computation to avoid full cost recalculation.

## üèóÔ∏è Architecture

### High-Level Pipeline

```
1. LSH Encoding: embeddings ‚Üí bucket codes
2. GTH Optimization: bucket codes ‚Üí optimized binary codes
3. Index Building: create mapping from codes to dataset indices
4. Query Time: 
   - Encode query ‚Üí bucket code
   - Apply GTH permutation ‚Üí optimized code
   - Expand Hamming ball around optimized code
   - Retrieve candidates from matching buckets
```

### Component Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Query Pipeline                       ‚îÇ
‚îÇ  query ‚Üí LSH ‚Üí GTH permutation ‚Üí Hamming ball ‚Üí results‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üë
                            ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Distribution-Aware Index                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
‚îÇ  ‚îÇ Traffic  ‚îÇ‚Üí ‚îÇ J(œÜ)     ‚îÇ‚Üí ‚îÇ GTH      ‚îÇ            ‚îÇ
‚îÇ  ‚îÇ Stats    ‚îÇ  ‚îÇ Objective‚îÇ  ‚îÇ Optimizer‚îÇ            ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üë
                            ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    LSH Encoder                          ‚îÇ
‚îÇ  embeddings ‚Üí bucket codes (Hyperplane/p-stable)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìÅ Project Structure

```
gray-tunneled-hashing/
‚îú‚îÄ‚îÄ src/gray_tunneled_hashing/     # Main package
‚îÇ   ‚îú‚îÄ‚îÄ algorithms/                # Core algorithms
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gray_tunneled_hasher.py    # Main GTH class
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ qap_objective.py           # QAP cost computation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ block_moves.py              # Block tunneling
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ block_selection.py          # Block selection strategies
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ simulated_annealing.py     # SA optimization
‚îÇ   ‚îú‚îÄ‚îÄ distribution/              # Distribution-aware components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ j_phi_objective.py         # J(œÜ) objective (Sprint 8)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cosine_objective.py         # Cosine distance objective
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ traffic_stats.py           # Query traffic statistics
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pipeline.py                 # End-to-end pipeline
‚îÇ   ‚îú‚îÄ‚îÄ api/                       # Public API
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ index_builder.py           # Index construction
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ query_pipeline.py          # Query-time pipeline
‚îÇ   ‚îú‚îÄ‚îÄ binary/                    # Binary code utilities
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lsh_families.py            # LSH implementations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ codebooks.py               # Codebook management
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ baselines.py               # Baseline methods
‚îÇ   ‚îú‚îÄ‚îÄ data/                      # Data handling
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ synthetic_generators.py    # Synthetic data
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ real_datasets.py            # Real dataset loaders
‚îÇ   ‚îú‚îÄ‚îÄ evaluation/                # Evaluation metrics
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metrics.py                 # Recall, precision, etc.
‚îÇ   ‚îî‚îÄ‚îÄ integrations/              # External integrations
‚îÇ       ‚îî‚îÄ‚îÄ hamming_index.py           # Hamming index wrapper
‚îú‚îÄ‚îÄ tests/                         # Test suite
‚îú‚îÄ‚îÄ scripts/                       # Utility scripts
‚îÇ   ‚îú‚îÄ‚îÄ run_sprint8_benchmark.py       # Benchmark script
‚îÇ   ‚îî‚îÄ‚îÄ analyze_sprint8_benchmark_results.py
‚îú‚îÄ‚îÄ experiments/                   # Experiments and results
‚îÇ   ‚îî‚îÄ‚îÄ real/
‚îÇ       ‚îú‚îÄ‚îÄ reports/                    # Analysis reports
‚îÇ       ‚îú‚îÄ‚îÄ results_json/               # JSON results (not versioned)
‚îÇ       ‚îî‚îÄ‚îÄ data/                        # Datasets
‚îî‚îÄ‚îÄ theory/                        # Theoretical documentation
    ‚îî‚îÄ‚îÄ THEORY_AND_RESEARCH_PROGRAM.md
```

## üîß Core Classes

### `GrayTunneledHasher`

Main class implementing the GTH algorithm.

**Key Methods**:
- `fit_with_traffic()`: Optimize permutation using distribution-aware objective
- `get_assignment()`: Get final permutation `(K, n_bits)` mapping buckets to codes
- `encode()`: Encode embeddings to binary codes (legacy)

**Sprint 8 Changes**:
- Permutation structure changed from `(N,)` to `(K, n_bits)` where `K` is number of buckets
- New objective `J(œÜ)` computed over real query-neighbor pairs
- Real embeddings objective: `compute_j_phi_cost_real_embeddings()`

### `build_distribution_aware_index()`

End-to-end pipeline for building a distribution-aware index.

**Steps**:
1. Compute traffic statistics (`œÄ`, `w`) from queries and ground truth
2. Initialize LSH encoder and create `code_to_bucket` mapping
3. Optimize GTH permutation using `J(œÜ)` objective
4. Build index mapping codes to dataset indices

### `query_with_hamming_ball()`

Query-time pipeline with Hamming ball expansion.

**Steps**:
1. Encode query ‚Üí bucket code `c_q`
2. Apply GTH permutation ‚Üí optimized code `cÃÉ_q = œÜ(c_q)`
3. Expand Hamming ball: `C_q(r) = {z : d_H(z, cÃÉ_q) ‚â§ r}`
4. Retrieve candidates from buckets whose permuted codes fall in ball

## üìñ API Reference

### Building an Index

```python
from gray_tunneled_hashing.api.index_builder import build_distribution_aware_index
from gray_tunneled_hashing.binary.lsh_families import create_lsh_family

# Create LSH encoder
encoder = create_lsh_family("hyperplane", n_bits=8, dim=64, random_state=42)

# Build index
index = build_distribution_aware_index(
    base_embeddings=base_embeddings,  # Shape (N, dim)
    queries=queries,                   # Shape (Q, dim)
    ground_truth_neighbors=gt_neighbors,  # Shape (Q, k)
    encoder=encoder,
    n_bits=8,
    n_codes=32,
    max_two_swap_iters=20,
    hamming_radius=1,
)

# index contains:
# - permutation: (K, n_bits) array
# - code_to_bucket: dict mapping codes to bucket indices
# - bucket_to_dataset_indices: dict mapping buckets to dataset indices
```

### Querying

```python
from gray_tunneled_hashing.api.query_pipeline import query_with_hamming_ball

# Query
result = query_with_hamming_ball(
    query_embedding=query,              # Shape (dim,)
    encoder=encoder,
    permutation=index["permutation"],   # Shape (K, n_bits)
    code_to_bucket=index["code_to_bucket"],
    bucket_to_dataset_indices=index["bucket_to_dataset_indices"],
    hamming_radius=1,
)

# result.candidate_indices contains candidate dataset indices
```

### Direct GTH Usage

```python
from gray_tunneled_hashing.algorithms.gray_tunneled_hasher import GrayTunneledHasher

hasher = GrayTunneledHasher(
    n_bits=8,
    max_two_swap_iters=20,
    num_tunneling_steps=0,
    mode="two_swap_only",
)

hasher.fit_with_traffic(
    queries=queries,
    base_embeddings=base_embeddings,
    ground_truth_neighbors=gt_neighbors,
    encoder=encoder,
    code_to_bucket=code_to_bucket,
    use_real_embeddings_objective=True,
)

permutation = hasher.get_assignment()  # Shape (K, n_bits)
```

## üöÄ Installation

### Requirements

- Python >= 3.10
- numpy
- scipy (for some LSH families)
- tqdm (for progress bars)

### Setup

```bash
git clone https://github.com/crbazevedo/gray-tunneled-hashing.git
cd gray-tunneled-hashing
pip install -e .
```

## üé¨ Quick Start

### Running the Benchmark

```bash
python scripts/run_sprint8_benchmark.py \
    --dataset synthetic \
    --n-bits 6,8 \
    --n-codes 16,32 \
    --k 10 \
    --hamming-radius 1,2 \
    --max-iters 10,20 \
    --output experiments/real/results_sprint8.json
```

### Analyzing Results

```bash
python scripts/analyze_sprint8_benchmark_results.py \
    --input experiments/real/results_sprint8.json \
    --output experiments/real/reports/analysis.md
```

### Basic Usage Example

```python
import numpy as np
from gray_tunneled_hashing.api.index_builder import build_distribution_aware_index
from gray_tunneled_hashing.binary.lsh_families import create_lsh_family
from gray_tunneled_hashing.api.query_pipeline import query_with_hamming_ball

# Generate synthetic data
np.random.seed(42)
base_embeddings = np.random.randn(1000, 64)
queries = np.random.randn(100, 64)

# Compute ground truth (simplified)
from sklearn.metrics.pairwise import cosine_similarity
gt_neighbors = cosine_similarity(queries, base_embeddings).argsort(axis=1)[:, -10:]

# Create encoder
encoder = create_lsh_family("hyperplane", n_bits=8, dim=64, random_state=42)

# Build index
index = build_distribution_aware_index(
    base_embeddings=base_embeddings,
    queries=queries,
    ground_truth_neighbors=gt_neighbors,
    encoder=encoder,
    n_bits=8,
    n_codes=32,
    max_two_swap_iters=10,
    hamming_radius=1,
)

# Query
result = query_with_hamming_ball(
    query_embedding=queries[0],
    encoder=encoder,
    permutation=index["permutation"],
    code_to_bucket=index["code_to_bucket"],
    bucket_to_dataset_indices=index["bucket_to_dataset_indices"],
    hamming_radius=1,
)

print(f"Found {len(result.candidate_indices)} candidates")
```

## üß™ Experiments

### Results Location

- **Reports**: `experiments/real/reports/`**
  - `SPRINT8_BENCHMARK_RESULTS_REPORT.md`: Complete analysis
  - `SPRINT8_BENCHMARK_ANALYSIS.md`: Automated analysis
  - `RECALL_RESULTS_SUMMARY.md`: Historical recall summary
- **JSON Results**: `experiments/real/results_json/` (not versioned)

### Key Findings (Sprint 8)

1. **GTH outperforms baselines** in 7/8 configurations
2. **Hyperplane LSH** works best with GTH (+61% to +91% improvements)
3. **p-stable LSH** shows smaller gains (+11% to +36%)
4. **J(œÜ) objective** successfully optimizes for recall on real embeddings

### Known Issues

1. **J(œÜ) correlation**: For `n_bits=8`, J(œÜ) worsens but recall improves (investigating)
2. **Build time**: ~100s per configuration (optimization opportunity)
3. **Hamming ball coverage**: Low (1-8%), may benefit from larger radius

## üìö Documentation

- **Theory**: `theory/THEORY_AND_RESEARCH_PROGRAM.md`
- **Development Notes**: `project_management/instructions/DEVELOPMENT_NOTES.md`
- **Sprint Log**: `project_management/sprints/sprint-log.md`
- **Experiments**: `experiments/real/README.md`

## ü§ù Contributing

See `project_management/instructions/CONTRIBUTING.md` for guidelines.

## üìÑ License

[Add license information]

## üôè Acknowledgments

[Add acknowledgments]

---

**Status**: Active development - Sprint 8 completed  
**Last Updated**: 2025-01-27
